# Fix: Server Ä‘ang dÃ¹ng Local LLM thay vÃ¬ API Mode

## Váº¥n Ä‘á»
Khi test chat trÃªn web, server Ä‘ang cháº¡y local LLM trÃªn mÃ¡y thay vÃ¬ gá»i HF Spaces API.

## NguyÃªn nhÃ¢n
1. **Global instance cache:** `get_llm_generator()` sá»­ dá»¥ng global instance `_llm_generator` chá»‰ táº¡o má»™t láº§n
2. **Server start vá»›i env cÅ©:** Náº¿u server start vá»›i `LLM_PROVIDER=local`, instance sáº½ giá»¯ provider=local
3. **KhÃ´ng reload khi env thay Ä‘á»•i:** Khi `.env` Ä‘Æ°á»£c update, server khÃ´ng tá»± Ä‘á»™ng reload instance

## ÄÃ£ sá»­a

### File: `backend/hue_portal/chatbot/llm_integration.py`

**TrÆ°á»›c:**
```python
_llm_generator: Optional[LLMGenerator] = None

def get_llm_generator() -> Optional[LLMGenerator]:
    global _llm_generator
    if _llm_generator is None:
        _llm_generator = LLMGenerator()
    return _llm_generator if _llm_generator.is_available() else None
```

**Sau:**
```python
_llm_generator: Optional[LLMGenerator] = None
_last_provider: Optional[str] = None

def get_llm_generator() -> Optional[LLMGenerator]:
    """Get or create LLM generator instance.
    
    Recreates instance if provider changed (e.g., from local to api).
    """
    global _llm_generator, _last_provider
    
    # Get current provider from env
    current_provider = os.environ.get("LLM_PROVIDER", LLM_PROVIDER_NONE).lower()
    
    # Recreate if provider changed or instance doesn't exist
    if _llm_generator is None or _last_provider != current_provider:
        _llm_generator = LLMGenerator()
        _last_provider = current_provider
        print(f"[LLM] ğŸ”„ Recreated LLM generator with provider: {current_provider}", flush=True)
    
    return _llm_generator if _llm_generator.is_available() else None
```

## CÃ¡ch test

1. **Äáº£m báº£o `.env` cÃ³ Ä‘Ãºng config:**
```bash
cd backend
cat .env | grep LLM
# Should show:
# LLM_PROVIDER=api
# HF_API_BASE_URL=https://davidtran999-hue-portal-backend.hf.space/api
```

2. **Restart server:**
```bash
pkill -f "manage.py runserver"
cd backend && source venv/bin/activate && cd hue_portal
python3 manage.py runserver 0.0.0.0:8000
```

3. **Test trong web UI:**
- Má»Ÿ http://localhost:3000/chat
- Gá»­i cÃ¢u há»i: "Má»©c pháº¡t vÆ°á»£t Ä‘Ã¨n Ä‘á» lÃ  bao nhiÃªu?"
- Xem server logs Ä‘á»ƒ tháº¥y:
  - `[LLM] ğŸ”„ Recreated LLM generator with provider: api`
  - `[RAG] Using LLM provider: api`
  - `[LLM] ğŸ”— Calling API: https://davidtran999-hue-portal-backend.hf.space/api/chatbot/chat/`

4. **Kiá»ƒm tra response:**
- Response pháº£i tá»« HF Spaces API (cÃ³ vÄƒn báº£n tá»± nhiÃªn, khÃ´ng pháº£i template)
- KHÃ”NG tháº¥y logs vá» local model loading

## LÆ°u Ã½

- Server sáº½ tá»± Ä‘á»™ng recreate LLM instance khi provider thay Ä‘á»•i
- KhÃ´ng cáº§n restart server khi thay Ä‘á»•i `.env` (nhÆ°ng nÃªn restart Ä‘á»ƒ Ä‘áº£m báº£o)
- Náº¿u váº«n dÃ¹ng local LLM, kiá»ƒm tra:
  - `.env` cÃ³ `LLM_PROVIDER=api` khÃ´ng
  - Server cÃ³ load Ä‘Ãºng `.env` khÃ´ng
  - Xem server logs Ä‘á»ƒ biáº¿t provider nÃ o Ä‘ang Ä‘Æ°á»£c dÃ¹ng




