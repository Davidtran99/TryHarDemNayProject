#!/usr/bin/env python3
"""
Script n√¢ng c·∫•p: T·ª± ƒë·ªông nh·∫≠n di·ªán v√† ƒë·∫∑t labels ch√≠nh x√°c b·∫±ng Computer Vision
S·ª≠ d·ª•ng OpenCV ƒë·ªÉ ph√°t hi·ªán c√°c annotation m√†u ƒë·ªè v√† t·ª± ƒë·ªông ƒë·∫∑t labels
"""

from PIL import Image, ImageDraw, ImageFont
import numpy as np
import cv2
import os
import sys

def detect_red_annotations(image_path):
    """
    Ph√°t hi·ªán c√°c annotation m√†u ƒë·ªè trong ·∫£nh b·∫±ng OpenCV
    Tr·∫£ v·ªÅ danh s√°ch c√°c bounding boxes v√† lo·∫°i annotation
    """
    # ƒê·ªçc ·∫£nh b·∫±ng OpenCV
    img_cv = cv2.imread(image_path)
    if img_cv is None:
        raise ValueError(f"Kh√¥ng th·ªÉ ƒë·ªçc file: {image_path}")
    
    # Chuy·ªÉn sang HSV ƒë·ªÉ d·ªÖ ph√°t hi·ªán m√†u ƒë·ªè
    hsv = cv2.cvtColor(img_cv, cv2.COLOR_BGR2HSV)
    
    # Ph·∫°m vi m√†u ƒë·ªè trong HSV (2 ph·∫°m vi v√¨ m√†u ƒë·ªè n·∫±m ·ªü c·∫£ 2 ƒë·∫ßu c·ªßa spectrum)
    lower_red1 = np.array([0, 50, 50])
    upper_red1 = np.array([10, 255, 255])
    lower_red2 = np.array([170, 50, 50])
    upper_red2 = np.array([180, 255, 255])
    
    # T·∫°o mask cho m√†u ƒë·ªè
    mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
    mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
    mask = cv2.bitwise_or(mask1, mask2)
    
    # L√†m m·ªãn mask
    kernel = np.ones((3, 3), np.uint8)
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
    
    # T√¨m contours
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    annotations = []
    
    for contour in contours:
        # L·ªçc c√°c contour qu√° nh·ªè (nhi·ªÖu)
        area = cv2.contourArea(contour)
        if area < 50:  # B·ªè qua c√°c v√πng qu√° nh·ªè
            continue
        
        # L·∫•y bounding box
        x, y, w, h = cv2.boundingRect(contour)
        
        # Ph√¢n lo·∫°i annotation d·ª±a tr√™n h√¨nh d·∫°ng v√† k√≠ch th∆∞·ªõc
        aspect_ratio = w / h if h > 0 else 0
        annotation_type = classify_annotation(x, y, w, h, area, aspect_ratio, contour, img_cv.shape)
        
        if annotation_type:
            annotations.append({
                'bbox': (x, y, w, h),
                'center': (x + w//2, y + h//2),
                'type': annotation_type,
                'area': area
            })
    
    return annotations, mask

def classify_annotation(x, y, w, h, area, aspect_ratio, contour, img_shape):
    """
    Ph√¢n lo·∫°i annotation d·ª±a tr√™n h√¨nh d·∫°ng, k√≠ch th∆∞·ªõc v√† v·ªã tr√≠
    """
    img_height, img_width = img_shape[:2]
    
    # T√≠nh v·ªã tr√≠ t∆∞∆°ng ƒë·ªëi
    rel_x = x / img_width
    rel_y = y / img_height
    rel_center_x = (x + w/2) / img_width
    rel_center_y = (y + h/2) / img_height
    
    # H·ªì l·ªõn (h√¨nh ch·ªØ nh·∫≠t l·ªõn, ·ªü upper-left-center)
    if area > 5000 and 0.15 < rel_x < 0.4 and 0.1 < rel_y < 0.4:
        if 0.8 < aspect_ratio < 1.5 or 0.6 < aspect_ratio < 1.2:
            return 'lake_large'
    
    # H·ªì nh·ªè (h√¨nh oval, ·ªü right-center)
    if area > 2000 and 0.5 < rel_x < 0.85 and 0.2 < rel_y < 0.5:
        if 0.7 < aspect_ratio < 1.5:
            return 'lake_small'
    
    # Nh√† ·ªü gi·ªØa h·ªì l·ªõn (h√¨nh ch·ªØ nh·∫≠t nh·ªè, ·ªü gi·ªØa h·ªì l·ªõn)
    if 500 < area < 3000 and 0.2 < rel_center_x < 0.4 and 0.15 < rel_center_y < 0.35:
        if 0.7 < aspect_ratio < 1.5:
            return 'house_center'
    
    # Cano ·ªü h·ªì nh·ªè (h√¨nh oval nh·ªè, ·ªü gi·ªØa h·ªì nh·ªè)
    if 100 < area < 800 and 0.55 < rel_center_x < 0.75 and 0.25 < rel_center_y < 0.45:
        if 0.6 < aspect_ratio < 1.4:
            return 'canoe'
    
    # Nh√† g·ªó 1 (h√¨nh ch·ªØ nh·∫≠t, gi·ªØa 2 h·ªì)
    if 300 < area < 2000 and 0.35 < rel_center_x < 0.5 and 0.3 < rel_center_y < 0.5:
        if 0.6 < aspect_ratio < 1.5:
            return 'house_wood1'
    
    # Nh√† g·ªó 2 (h√¨nh ch·ªØ L, gi·ªØa 2 h·ªì, b√™n ph·∫£i h·ªì l·ªõn)
    # Ki·ªÉm tra h√¨nh ch·ªØ L b·∫±ng c√°ch ph√¢n t√≠ch contour
    if 300 < area < 2000 and 0.4 < rel_center_x < 0.55 and 0.35 < rel_center_y < 0.55:
        # Ki·ªÉm tra xem c√≥ ph·∫£i h√¨nh L kh√¥ng (c√≥ g√≥c vu√¥ng)
        approx = cv2.approxPolyDP(contour, 0.02 * cv2.arcLength(contour, True), True)
        if len(approx) >= 4:  # C√≥ nhi·ªÅu g√≥c
            return 'house_wood2_L'
    
    # C·∫ßu g·ªó (ƒë∆∞·ªùng th·∫≥ng d·ªçc, far left)
    if area > 200 and 0.02 < rel_x < 0.15:
        if aspect_ratio < 0.3 or h > w * 3:  # D·ªçc
            return 'bridge_vertical'
    
    # C·ªïng g·ªó (·ªü cu·ªëi c·∫ßu g·ªó d·ªçc, ph√≠a d∆∞·ªõi)
    # C√πng v·ªã tr√≠ x v·ªõi c·∫ßu g·ªó, nh∆∞ng ·ªü cu·ªëi (y l·ªõn h∆°n)
    if 200 < area < 2000 and 0.02 < rel_center_x < 0.18:
        # ·ªû cu·ªëi c·∫ßu g·ªó (ph√≠a d∆∞·ªõi), y t·ª´ 0.5 ƒë·∫øn 0.85
        if 0.5 < rel_center_y < 0.85:
            # C√≥ th·ªÉ l√† h√¨nh ch·ªØ L ho·∫∑c h√¨nh ch·ªØ nh·∫≠t
            approx = cv2.approxPolyDP(contour, 0.02 * cv2.arcLength(contour, True), True)
            # N·∫øu l√† h√¨nh ch·ªØ L (nhi·ªÅu g√≥c) ho·∫∑c h√¨nh ch·ªØ nh·∫≠t (4 g√≥c)
            if len(approx) >= 4:
                return 'gate'
    
    # Khu v·ª±c ƒë·∫•t ƒë·∫Øp cao (v√πng s√°ng, bottom-center)
    if area > 1000 and 0.4 < rel_center_x < 0.6 and 0.65 < rel_center_y < 0.85:
        return 'park'
    
    return None

def detect_dotted_lines(image_path):
    """
    Ph√°t hi·ªán c√°c ƒë∆∞·ªùng ch·∫•m ch·∫•m (dotted lines) - c√¢y th√¥ng
    """
    img_cv = cv2.imread(image_path)
    hsv = cv2.cvtColor(img_cv, cv2.COLOR_BGR2HSV)
    
    # Mask cho m√†u ƒë·ªè
    lower_red1 = np.array([0, 50, 50])
    upper_red1 = np.array([10, 255, 255])
    lower_red2 = np.array([170, 50, 50])
    upper_red2 = np.array([180, 255, 255])
    mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
    mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
    mask = cv2.bitwise_or(mask1, mask2)
    
    # T√¨m c√°c ƒëi·ªÉm ƒë·ªè nh·ªè (dots)
    kernel = np.ones((2, 2), np.uint8)
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
    
    # T√¨m contours c·ªßa c√°c dots
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # L·ªçc c√°c dots nh·ªè (c√¢y th√¥ng)
    dots = []
    for contour in contours:
        area = cv2.contourArea(contour)
        if 10 < area < 200:  # Dots nh·ªè
            x, y, w, h = cv2.boundingRect(contour)
            dots.append((x + w//2, y + h//2))
    
    # T√¨m ƒë∆∞·ªùng ch·∫•m ch·∫•m (dots g·∫ßn nhau t·∫°o th√†nh ƒë∆∞·ªùng)
    if len(dots) > 10:
        # T√≠nh trung b√¨nh v·ªã tr√≠ c·ªßa c√°c dots
        avg_x = sum(d[0] for d in dots) / len(dots)
        avg_y = sum(d[1] for d in dots) / len(dots)
        return (int(avg_x), int(avg_y))
    
    return None

def edit_satellite_image_advanced(input_path, output_path):
    """
    Ch·ªânh s·ª≠a ·∫£nh v·ªá tinh v·ªõi nh·∫≠n di·ªán t·ª± ƒë·ªông
    """
    print("üîç ƒêang ph√¢n t√≠ch ·∫£nh v√† ph√°t hi·ªán c√°c annotation...")
    
    # Ph√°t hi·ªán c√°c annotation m√†u ƒë·ªè
    annotations, mask = detect_red_annotations(input_path)
    
    print(f"‚úÖ ƒê√£ ph√°t hi·ªán {len(annotations)} annotation(s)")
    
    # Ph√°t hi·ªán ƒë∆∞·ªùng ch·∫•m ch·∫•m (c√¢y th√¥ng)
    pine_location = detect_dotted_lines(input_path)
    
    # M·ªü ·∫£nh b·∫±ng PIL ƒë·ªÉ v·∫Ω labels
    img = Image.open(input_path)
    draw = ImageDraw.Draw(img)
    
    # Load font
    try:
        font_large = ImageFont.truetype("/System/Library/Fonts/Helvetica.ttc", 24)
        font_medium = ImageFont.truetype("/System/Library/Fonts/Helvetica.ttc", 18)
        font_small = ImageFont.truetype("/System/Library/Fonts/Helvetica.ttc", 14)
    except:
        try:
            font_large = ImageFont.truetype("arial.ttf", 24)
            font_medium = ImageFont.truetype("arial.ttf", 18)
            font_small = ImageFont.truetype("arial.ttf", 14)
        except:
            font_large = ImageFont.load_default()
            font_medium = ImageFont.load_default()
            font_small = ImageFont.load_default()
    
    width, height = img.size
    
    # M√†u s·∫Øc
    RED = (255, 0, 0)
    BLUE = (0, 0, 255)
    GREEN = (0, 255, 0)
    YELLOW = (255, 255, 0)
    WHITE = (255, 255, 255)
    BLACK = (0, 0, 0)
    ORANGE = (255, 165, 0)
    
    def draw_label(draw, x, y, text, bg_color=WHITE, text_color=BLACK, font=font_medium):
        """V·∫Ω label v·ªõi background v√† border"""
        bbox = draw.textbbox((0, 0), text, font=font)
        text_width = bbox[2] - bbox[0]
        text_height = bbox[3] - bbox[1]
        
        padding = 8
        rect_x1 = x - padding
        rect_y1 = y - padding
        rect_x2 = x + text_width + padding
        rect_y2 = y + text_height + padding
        
        draw.rectangle([rect_x1, rect_y1, rect_x2, rect_y2], fill=bg_color, outline=RED, width=2)
        draw.text((x, y), text, fill=text_color, font=font)
    
    # Mapping labels
    label_map = {
        'lake_large': ('H·ªí L·ªöN\n(H√¨nh ch·ªØ nh·∫≠t)', YELLOW, BLACK, font_medium),
        'lake_small': ('H·ªí NH·ªé\n(H√¨nh oval)', YELLOW, BLACK, font_medium),
        'house_center': ('NH√Ä TR·∫ÆNG\n(·ªû gi·ªØa h·ªì)', WHITE, BLACK, font_small),
        'canoe': ('CANO\n(·ªû gi·ªØa h·ªì)', WHITE, BLACK, font_small),
        'house_wood1': ('NH√Ä G·ªñ 1', GREEN, WHITE, font_medium),
        'house_wood2_L': ('NH√Ä G·ªñ 2\n(H√¨nh ch·ªØ L)', GREEN, WHITE, font_medium),
        'bridge_vertical': ('C·∫¶U G·ªñ\n(ƒê∆∞·ªùng d·ªçc)', BLUE, WHITE, font_medium),
        'gate': ('C·ªîNG G·ªñ\n(C√≥ m√°i hoa gi·∫•y)', RED, WHITE, font_medium),
        'park': ('ƒê·∫§T ƒê·∫ÆP CAO\n(Park)', YELLOW, BLACK, font_medium),
    }
    
    # T√¨m c·∫ßu g·ªó ƒë·ªÉ x√°c ƒë·ªãnh v·ªã tr√≠ c·ªïng g·ªó
    bridge_vertical = None
    for ann in annotations:
        if ann['type'] == 'bridge_vertical':
            bridge_vertical = ann
            break
    
    # V·∫Ω labels cho c√°c annotation ƒë√£ ph√°t hi·ªán
    detected_types = {}
    for ann in annotations:
        ann_type = ann['type']
        if ann_type and ann_type in label_map:
            # Tr√°nh duplicate
            if ann_type not in detected_types:
                center_x, center_y = ann['center']
                text, bg_color, text_color, font = label_map[ann_type]
                
                # ƒêi·ªÅu ch·ªânh v·ªã tr√≠ label ƒë·ªÉ kh√¥ng che annotation
                label_x = center_x + 20
                label_y = center_y - 20
                
                # ƒê·∫∑c bi·ªát cho c·ªïng g·ªó: ƒë·∫∑t ·ªü cu·ªëi c·∫ßu g·ªó
                if ann_type == 'gate' and bridge_vertical:
                    # C·ªïng g·ªó ·ªü cu·ªëi (ph√≠a d∆∞·ªõi) c·∫ßu g·ªó
                    bridge_x, bridge_y, bridge_w, bridge_h = bridge_vertical['bbox']
                    # Cu·ªëi c·∫ßu g·ªó l√† bottom c·ªßa bounding box
                    gate_y = bridge_y + bridge_h
                    label_x = center_x + 20
                    label_y = gate_y + 10  # ƒê·∫∑t label ngay d∆∞·ªõi c·ªïng g·ªó
                
                draw_label(draw, label_x, label_y, text, bg_color, text_color, font)
                detected_types[ann_type] = True
                
                print(f"  ‚úì ƒê√£ ƒë·∫∑t label: {ann_type} t·∫°i ({center_x}, {center_y})")
    
    # V·∫Ω label cho c√¢y th√¥ng n·∫øu ph√°t hi·ªán ƒë∆∞·ª£c
    if pine_location:
        pine_x, pine_y = pine_location
        draw_label(draw, pine_x + 20, pine_y - 20, 'C√ÇY TH√îNG V√ÄNG\n(Dotted line)', 
                  GREEN, WHITE, font_small)
        print(f"  ‚úì ƒê√£ ƒë·∫∑t label: C√¢y th√¥ng t·∫°i ({pine_x}, {pine_y})")
    
    # Th√™m label c·∫£nh b√°o v·ªÅ h·ªì s·∫Ω b·ªã l·∫•p
    for ann in annotations:
        if ann['type'] == 'lake_small':
            center_x, center_y = ann['center']
            draw_label(draw, center_x + 20, center_y + 30, '‚ö†Ô∏è H·ªí N√ÄY\nS·∫º B·ªä L·∫§P', 
                      RED, WHITE, font_medium)
            break
    
    # V·∫Ω title
    title = "B·∫¢N V·∫º THI·∫æT K·∫æ - T·ª∞ ƒê·ªòNG NH·∫¨N DI·ªÜN"
    title_bbox = draw.textbbox((0, 0), title, font=font_large)
    title_width = title_bbox[2] - title_bbox[0]
    title_x = (width - title_width) // 2
    draw_label(draw, title_x, 20, title, BLACK, WHITE, font_large)
    
    # L∆∞u ·∫£nh
    img.save(output_path, quality=95)
    print(f"\n‚úÖ ƒê√£ l∆∞u ·∫£nh ƒë√£ ch·ªânh s·ª≠a t·∫°i: {output_path}")
    print(f"üìè K√≠ch th∆∞·ªõc ·∫£nh: {width}x{height} pixels")
    print(f"üìä ƒê√£ ph√°t hi·ªán v√† ƒë·∫∑t {len(detected_types)} label(s)")

def main():
    """H√†m main"""
    if len(sys.argv) < 2:
        print("üìñ C√°ch s·ª≠ d·ª•ng:")
        print("  python edit_satellite_image_advanced.py <ƒë∆∞·ªùng_d·∫´n_·∫£nh_g·ªëc> [ƒë∆∞·ªùng_d·∫´n_·∫£nh_output]")
        print("\nV√≠ d·ª•:")
        print("  python edit_satellite_image_advanced.py satellite_image.png")
        return
    
    input_path = sys.argv[1]
    
    if not os.path.exists(input_path):
        print(f"‚ùå File kh√¥ng t·ªìn t·∫°i: {input_path}")
        return
    
    if len(sys.argv) >= 3:
        output_path = sys.argv[2]
    else:
        base_name = os.path.splitext(input_path)[0]
        ext = os.path.splitext(input_path)[1]
        output_path = f"{base_name}_auto_detected{ext}"
    
    try:
        edit_satellite_image_advanced(input_path, output_path)
        print("\n‚ú® Ho√†n th√†nh!")
    except Exception as e:
        print(f"‚ùå L·ªói: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()

